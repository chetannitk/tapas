{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sqa_predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZbLp8eoQSF8z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetannitk/tapas/blob/master/notebooks/sqa_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKB8YaRk05Sl",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/tapas/blob/master/notebooks/sqa_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-07bRHwv0C7L",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The Google AI Language Team Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpOxRRH0BCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EACclxE7sP",
        "colab_type": "text"
      },
      "source": [
        "Running a Tapas fine-tuned checkpoint\n",
        "---\n",
        "This notebook shows how to load and make predictions with TAPAS model, which was introduced in the paper: [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-m_JoVCFCV0",
        "colab_type": "text"
      },
      "source": [
        "# Clone and install the repository\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF84Z-KayR3Z",
        "colab_type": "text"
      },
      "source": [
        "First, let's fetch the code from the github repository and install it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI6zyIM20Kw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "af0df09e-3bc9-47c7-88ac-3b84b0aa7085"
      },
      "source": [
        "! git clone https://github.com/google-research/tapas.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tapas'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/109)\u001b[K\rremote: Counting objects:   1% (2/109)\u001b[K\rremote: Counting objects:   2% (3/109)\u001b[K\rremote: Counting objects:   3% (4/109)\u001b[K\rremote: Counting objects:   4% (5/109)\u001b[K\rremote: Counting objects:   5% (6/109)\u001b[K\rremote: Counting objects:   6% (7/109)\u001b[K\rremote: Counting objects:   7% (8/109)\u001b[K\rremote: Counting objects:   8% (9/109)\u001b[K\rremote: Counting objects:   9% (10/109)\u001b[K\rremote: Counting objects:  10% (11/109)\u001b[K\rremote: Counting objects:  11% (12/109)\u001b[K\rremote: Counting objects:  12% (14/109)\u001b[K\rremote: Counting objects:  13% (15/109)\u001b[K\rremote: Counting objects:  14% (16/109)\u001b[K\rremote: Counting objects:  15% (17/109)\u001b[K\rremote: Counting objects:  16% (18/109)\u001b[K\rremote: Counting objects:  17% (19/109)\u001b[K\rremote: Counting objects:  18% (20/109)\u001b[K\rremote: Counting objects:  19% (21/109)\u001b[K\rremote: Counting objects:  20% (22/109)\u001b[K\rremote: Counting objects:  21% (23/109)\u001b[K\rremote: Counting objects:  22% (24/109)\u001b[K\rremote: Counting objects:  23% (26/109)\u001b[K\rremote: Counting objects:  24% (27/109)\u001b[K\rremote: Counting objects:  25% (28/109)\u001b[K\rremote: Counting objects:  26% (29/109)\u001b[K\rremote: Counting objects:  27% (30/109)\u001b[K\rremote: Counting objects:  28% (31/109)\u001b[K\rremote: Counting objects:  29% (32/109)\u001b[K\rremote: Counting objects:  30% (33/109)\u001b[K\rremote: Counting objects:  31% (34/109)\u001b[K\rremote: Counting objects:  32% (35/109)\u001b[K\rremote: Counting objects:  33% (36/109)\u001b[K\rremote: Counting objects:  34% (38/109)\u001b[K\rremote: Counting objects:  35% (39/109)\u001b[K\rremote: Counting objects:  36% (40/109)\u001b[K\rremote: Counting objects:  37% (41/109)\u001b[K\rremote: Counting objects:  38% (42/109)\u001b[K\rremote: Counting objects:  39% (43/109)\u001b[K\rremote: Counting objects:  40% (44/109)\u001b[K\rremote: Counting objects:  41% (45/109)\u001b[K\rremote: Counting objects:  42% (46/109)\u001b[K\rremote: Counting objects:  43% (47/109)\u001b[K\rremote: Counting objects:  44% (48/109)\u001b[K\rremote: Counting objects:  45% (50/109)\u001b[K\rremote: Counting objects:  46% (51/109)\u001b[K\rremote: Counting objects:  47% (52/109)\u001b[K\rremote: Counting objects:  48% (53/109)\u001b[K\rremote: Counting objects:  49% (54/109)\u001b[K\rremote: Counting objects:  50% (55/109)\u001b[K\rremote: Counting objects:  51% (56/109)\u001b[K\rremote: Counting objects:  52% (57/109)\u001b[K\rremote: Counting objects:  53% (58/109)\u001b[K\rremote: Counting objects:  54% (59/109)\u001b[K\rremote: Counting objects:  55% (60/109)\u001b[K\rremote: Counting objects:  56% (62/109)\u001b[K\rremote: Counting objects:  57% (63/109)\u001b[K\rremote: Counting objects:  58% (64/109)\u001b[K\rremote: Counting objects:  59% (65/109)\u001b[K\rremote: Counting objects:  60% (66/109)\u001b[K\rremote: Counting objects:  61% (67/109)\u001b[K\rremote: Counting objects:  62% (68/109)\u001b[K\rremote: Counting objects:  63% (69/109)\u001b[K\rremote: Counting objects:  64% (70/109)\u001b[K\rremote: Counting objects:  65% (71/109)\u001b[K\rremote: Counting objects:  66% (72/109)\u001b[K\rremote: Counting objects:  67% (74/109)\u001b[K\rremote: Counting objects:  68% (75/109)\u001b[K\rremote: Counting objects:  69% (76/109)\u001b[K\rremote: Counting objects:  70% (77/109)\u001b[K\rremote: Counting objects:  71% (78/109)\u001b[K\rremote: Counting objects:  72% (79/109)\u001b[K\rremote: Counting objects:  73% (80/109)\u001b[K\rremote: Counting objects:  74% (81/109)\u001b[K\rremote: Counting objects:  75% (82/109)\u001b[K\rremote: Counting objects:  76% (83/109)\u001b[K\rremote: Counting objects:  77% (84/109)\u001b[K\rremote: Counting objects:  78% (86/109)\u001b[K\rremote: Counting objects:  79% (87/109)\u001b[K\rremote: Counting objects:  80% (88/109)\u001b[K\rremote: Counting objects:  81% (89/109)\u001b[K\rremote: Counting objects:  82% (90/109)\u001b[K\rremote: Counting objects:  83% (91/109)\u001b[K\rremote: Counting objects:  84% (92/109)\u001b[K\rremote: Counting objects:  85% (93/109)\u001b[K\rremote: Counting objects:  86% (94/109)\u001b[K\rremote: Counting objects:  87% (95/109)\u001b[K\rremote: Counting objects:  88% (96/109)\u001b[K\rremote: Counting objects:  89% (98/109)\u001b[K\rremote: Counting objects:  90% (99/109)\u001b[K\rremote: Counting objects:  91% (100/109)\u001b[K\rremote: Counting objects:  92% (101/109)\u001b[K\rremote: Counting objects:  93% (102/109)\u001b[K\rremote: Counting objects:  94% (103/109)\u001b[K\rremote: Counting objects:  95% (104/109)\u001b[K\rremote: Counting objects:  96% (105/109)\u001b[K\rremote: Counting objects:  97% (106/109)\u001b[K\rremote: Counting objects:  98% (107/109)\u001b[K\rremote: Counting objects:  99% (108/109)\u001b[K\rremote: Counting objects: 100% (109/109)\u001b[K\rremote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/84)\u001b[K\rremote: Compressing objects:   2% (2/84)\u001b[K\rremote: Compressing objects:   3% (3/84)\u001b[K\rremote: Compressing objects:   4% (4/84)\u001b[K\rremote: Compressing objects:   5% (5/84)\u001b[K\rremote: Compressing objects:   7% (6/84)\u001b[K\rremote: Compressing objects:   8% (7/84)\u001b[K\rremote: Compressing objects:   9% (8/84)\u001b[K\rremote: Compressing objects:  10% (9/84)\u001b[K\rremote: Compressing objects:  11% (10/84)\u001b[K\rremote: Compressing objects:  13% (11/84)\u001b[K\rremote: Compressing objects:  14% (12/84)\u001b[K\rremote: Compressing objects:  15% (13/84)\u001b[K\rremote: Compressing objects:  16% (14/84)\u001b[K\rremote: Compressing objects:  17% (15/84)\u001b[K\rremote: Compressing objects:  19% (16/84)\u001b[K\rremote: Compressing objects:  20% (17/84)\u001b[K\rremote: Compressing objects:  21% (18/84)\u001b[K\rremote: Compressing objects:  22% (19/84)\u001b[K\rremote: Compressing objects:  23% (20/84)\u001b[K\rremote: Compressing objects:  25% (21/84)\u001b[K\rremote: Compressing objects:  26% (22/84)\u001b[K\rremote: Compressing objects:  27% (23/84)\u001b[K\rremote: Compressing objects:  28% (24/84)\u001b[K\rremote: Compressing objects:  29% (25/84)\u001b[K\rremote: Compressing objects:  30% (26/84)\u001b[K\rremote: Compressing objects:  32% (27/84)\u001b[K\rremote: Compressing objects:  33% (28/84)\u001b[K\rremote: Compressing objects:  34% (29/84)\u001b[K\rremote: Compressing objects:  35% (30/84)\u001b[K\rremote: Compressing objects:  36% (31/84)\u001b[K\rremote: Compressing objects:  38% (32/84)\u001b[K\rremote: Compressing objects:  39% (33/84)\u001b[K\rremote: Compressing objects:  40% (34/84)\u001b[K\rremote: Compressing objects:  41% (35/84)\u001b[K\rremote: Compressing objects:  42% (36/84)\u001b[K\rremote: Compressing objects:  44% (37/84)\u001b[K\rremote: Compressing objects:  45% (38/84)\u001b[K\rremote: Compressing objects:  46% (39/84)\u001b[K\rremote: Compressing objects:  47% (40/84)\u001b[K\rremote: Compressing objects:  48% (41/84)\u001b[K\rremote: Compressing objects:  50% (42/84)\u001b[K\rremote: Compressing objects:  51% (43/84)\u001b[K\rremote: Compressing objects:  52% (44/84)\u001b[K\rremote: Compressing objects:  53% (45/84)\u001b[K\rremote: Compressing objects:  54% (46/84)\u001b[K\rremote: Compressing objects:  55% (47/84)\u001b[K\rremote: Compressing objects:  57% (48/84)\u001b[K\rremote: Compressing objects:  58% (49/84)\u001b[K\rremote: Compressing objects:  59% (50/84)\u001b[K\rremote: Compressing objects:  60% (51/84)\u001b[K\rremote: Compressing objects:  61% (52/84)\u001b[K\rremote: Compressing objects:  63% (53/84)\u001b[K\rremote: Compressing objects:  64% (54/84)\u001b[K\rremote: Compressing objects:  65% (55/84)\u001b[K\rremote: Compressing objects:  66% (56/84)\u001b[K\rremote: Compressing objects:  67% (57/84)\u001b[K\rremote: Compressing objects:  69% (58/84)\u001b[K\rremote: Compressing objects:  70% (59/84)\u001b[K\rremote: Compressing objects:  71% (60/84)\u001b[K\rremote: Compressing objects:  72% (61/84)\u001b[K\rremote: Compressing objects:  73% (62/84)\u001b[K\rremote: Compressing objects:  75% (63/84)\u001b[K\rremote: Compressing objects:  76% (64/84)\u001b[K\rremote: Compressing objects:  77% (65/84)\u001b[K\rremote: Compressing objects:  78% (66/84)\u001b[K\rremote: Compressing objects:  79% (67/84)\u001b[K\rremote: Compressing objects:  80% (68/84)\u001b[K\rremote: Compressing objects:  82% (69/84)\u001b[K\rremote: Compressing objects:  83% (70/84)\u001b[K\rremote: Compressing objects:  84% (71/84)\u001b[K\rremote: Compressing objects:  85% (72/84)\u001b[K\rremote: Compressing objects:  86% (73/84)\u001b[K\rremote: Compressing objects:  88% (74/84)\u001b[K\rremote: Compressing objects:  89% (75/84)\u001b[K\rremote: Compressing objects:  90% (76/84)\u001b[K\rremote: Compressing objects:  91% (77/84)\u001b[K\rremote: Compressing objects:  92% (78/84)\u001b[K\rremote: Compressing objects:  94% (79/84)\u001b[K\rremote: Compressing objects:  95% (80/84)\u001b[K\rremote: Compressing objects:  96% (81/84)\u001b[K\rremote: Compressing objects:  97% (82/84)\u001b[K\rremote: Compressing objects:  98% (83/84)\u001b[K\rremote: Compressing objects: 100% (84/84)\u001b[K\rremote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "Receiving objects:   0% (1/109)   \rReceiving objects:   1% (2/109)   \rReceiving objects:   2% (3/109)   \rReceiving objects:   3% (4/109)   \rReceiving objects:   4% (5/109)   \rReceiving objects:   5% (6/109)   \rReceiving objects:   6% (7/109)   \rReceiving objects:   7% (8/109)   \rReceiving objects:   8% (9/109)   \rReceiving objects:   9% (10/109)   \rReceiving objects:  10% (11/109)   \rReceiving objects:  11% (12/109)   \rReceiving objects:  12% (14/109)   \rReceiving objects:  13% (15/109)   \rReceiving objects:  14% (16/109)   \rReceiving objects:  15% (17/109)   \rReceiving objects:  16% (18/109)   \rReceiving objects:  17% (19/109)   \rReceiving objects:  18% (20/109)   \rReceiving objects:  19% (21/109)   \rReceiving objects:  20% (22/109)   \rReceiving objects:  21% (23/109)   \rReceiving objects:  22% (24/109)   \rReceiving objects:  23% (26/109)   \rReceiving objects:  24% (27/109)   \rReceiving objects:  25% (28/109)   \rReceiving objects:  26% (29/109)   \rReceiving objects:  27% (30/109)   \rReceiving objects:  28% (31/109)   \rReceiving objects:  29% (32/109)   \rReceiving objects:  30% (33/109)   \rReceiving objects:  31% (34/109)   \rReceiving objects:  32% (35/109)   \rReceiving objects:  33% (36/109)   \rReceiving objects:  34% (38/109)   \rReceiving objects:  35% (39/109)   \rReceiving objects:  36% (40/109)   \rReceiving objects:  37% (41/109)   \rReceiving objects:  38% (42/109)   \rReceiving objects:  39% (43/109)   \rReceiving objects:  40% (44/109)   \rReceiving objects:  41% (45/109)   \rReceiving objects:  42% (46/109)   \rReceiving objects:  43% (47/109)   \rReceiving objects:  44% (48/109)   \rReceiving objects:  45% (50/109)   \rReceiving objects:  46% (51/109)   \rReceiving objects:  47% (52/109)   \rReceiving objects:  48% (53/109)   \rReceiving objects:  49% (54/109)   \rReceiving objects:  50% (55/109)   \rReceiving objects:  51% (56/109)   \rReceiving objects:  52% (57/109)   \rReceiving objects:  53% (58/109)   \rReceiving objects:  54% (59/109)   \rReceiving objects:  55% (60/109)   \rReceiving objects:  56% (62/109)   \rReceiving objects:  57% (63/109)   \rReceiving objects:  58% (64/109)   \rReceiving objects:  59% (65/109)   \rReceiving objects:  60% (66/109)   \rReceiving objects:  61% (67/109)   \rReceiving objects:  62% (68/109)   \rReceiving objects:  63% (69/109)   \rReceiving objects:  64% (70/109)   \rReceiving objects:  65% (71/109)   \rReceiving objects:  66% (72/109)   \rReceiving objects:  67% (74/109)   \rReceiving objects:  68% (75/109)   \rReceiving objects:  69% (76/109)   \rReceiving objects:  70% (77/109)   \rReceiving objects:  71% (78/109)   \rReceiving objects:  72% (79/109)   \rReceiving objects:  73% (80/109)   \rReceiving objects:  74% (81/109)   \rReceiving objects:  75% (82/109)   \rReceiving objects:  76% (83/109)   \rReceiving objects:  77% (84/109)   \rReceiving objects:  78% (86/109)   \rReceiving objects:  79% (87/109)   \rReceiving objects:  80% (88/109)   \rReceiving objects:  81% (89/109)   \rReceiving objects:  82% (90/109)   \rReceiving objects:  83% (91/109)   \rReceiving objects:  84% (92/109)   \rremote: Total 109 (delta 25), reused 103 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects:  85% (93/109)   \rReceiving objects:  86% (94/109)   \rReceiving objects:  87% (95/109)   \rReceiving objects:  88% (96/109)   \rReceiving objects:  89% (98/109)   \rReceiving objects:  90% (99/109)   \rReceiving objects:  91% (100/109)   \rReceiving objects:  92% (101/109)   \rReceiving objects:  93% (102/109)   \rReceiving objects:  94% (103/109)   \rReceiving objects:  95% (104/109)   \rReceiving objects:  96% (105/109)   \rReceiving objects:  97% (106/109)   \rReceiving objects:  98% (107/109)   \rReceiving objects:  99% (108/109)   \rReceiving objects: 100% (109/109)   \rReceiving objects: 100% (109/109), 154.25 KiB | 8.57 MiB/s, done.\n",
            "Resolving deltas:   0% (0/25)   \rResolving deltas:  16% (4/25)   \rResolving deltas:  20% (5/25)   \rResolving deltas:  28% (7/25)   \rResolving deltas:  32% (8/25)   \rResolving deltas:  44% (11/25)   \rResolving deltas:  48% (12/25)   \rResolving deltas:  52% (13/25)   \rResolving deltas:  56% (14/25)   \rResolving deltas:  60% (15/25)   \rResolving deltas:  64% (16/25)   \rResolving deltas:  68% (17/25)   \rResolving deltas:  76% (19/25)   \rResolving deltas:  80% (20/25)   \rResolving deltas:  84% (21/25)   \rResolving deltas:  88% (22/25)   \rResolving deltas:  92% (23/25)   \rResolving deltas:  96% (24/25)   \rResolving deltas: 100% (25/25)   \rResolving deltas: 100% (25/25), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PULx_0fmxbOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a5d8c1a-5c47-4faa-dff1-eec3ac94de51"
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install ./tapas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Successfully uninstalled tensorflow-2.2.0\n",
            "Processing ./tapas\n",
            "Collecting bert-tensorflow==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n",
            "\u001b[?25hCollecting frozendict==1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Requirement already satisfied: scikit-learn~=0.22.1 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (1.0.3)\n",
            "Collecting tensorflow-gpu~=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 37kB/s \n",
            "\u001b[?25hCollecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses~=0.7 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1->tapas==0.0.1.dev0) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (1.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0.0->tapas==0.0.1.dev0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0.0->tapas==0.0.1.dev0) (2018.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.29.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.12.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.10.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0->tapas==0.0.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0->tapas==0.0.1.dev0) (4.4.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.1.0)\n",
            "Building wheels for collected packages: tapas, frozendict\n",
            "  Building wheel for tapas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tapas: filename=tapas-0.0.1.dev0-cp36-none-any.whl size=153403 sha256=a152e0bc10d6ddb9329a97cfc2fa50a2895856de941601aacc74449a608955fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8gndw2pm/wheels/2f/0b/d5/7e7fd15d1eb9839bd9768eaa6af2e0446329927b0f0c351387\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp36-none-any.whl size=3149 sha256=a21306a752a4914a99f088bd531ddefba5519188b990646199442149c1e3c5dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "Successfully built tapas frozendict\n",
            "Installing collected packages: bert-tensorflow, frozendict, tensorboard, tensorflow-estimator, tensorflow-gpu, tensorflow-probability, tapas\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow-probability 0.10.0\n",
            "    Uninstalling tensorflow-probability-0.10.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.10.0\n",
            "Successfully installed bert-tensorflow-1.0.1 frozendict-1.2 tapas-0.0.1.dev0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 tensorflow-probability-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7We9ofHuFMuk",
        "colab_type": "text"
      },
      "source": [
        "# Fetch models fom Google Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA1jUByqyUNB",
        "colab_type": "text"
      },
      "source": [
        "Next we can get pretrained checkpoint from Google Storage. For the sake of speed, this is base sized model trained on [SQA](https://www.microsoft.com/en-us/download/details.aspx?id=54253). Note that best results in the paper were obtained with with a large model, with 24 layers instead of 12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10C0Yz6gQyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b86feef-f59f-4f27-8c8d-f0e5b478d789"
      },
      "source": [
        "! gsutil cp gs://tapas_models/2020_04_21/tapas_sqa_base.zip . && unzip tapas_sqa_base.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tapas_models/2020_04_21/tapas_sqa_base.zip...\n",
            "/ [1 files][  1.0 GiB/  1.0 GiB]   60.2 MiB/s                                   \n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n",
            "Archive:  tapas_sqa_base.zip\n",
            "   creating: tapas_sqa_base/\n",
            "  inflating: tapas_sqa_base/model.ckpt.data-00000-of-00001  \n",
            "  inflating: tapas_sqa_base/model.ckpt.index  \n",
            "  inflating: tapas_sqa_base/README.txt  \n",
            "  inflating: tapas_sqa_base/vocab.txt  \n",
            "  inflating: tapas_sqa_base/bert_config.json  \n",
            "  inflating: tapas_sqa_base/model.ckpt.meta  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3107bGlGm7d",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnUjDlLqDd3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "8e533961-31fa-4c7f-a7d6-3fd48b7e7d15"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import os \n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import IPython\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aml6oLFl1dSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tapas.utils import tf_example_utils\n",
        "from tapas.protos import interaction_pb2\n",
        "from tapas.utils import number_annotation_utils\n",
        "from tapas.scripts import prediction_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMUYT1bKMp9",
        "colab_type": "text"
      },
      "source": [
        "# Load checkpoint for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO0d_wFMy82O",
        "colab_type": "text"
      },
      "source": [
        "Here's the prediction code, which will create and `interaction_pb2.Interaction` protobuf object, which is the datastructure we use to store examples, and then call the prediction script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKfxspnVFPsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('results/sqa/tf_examples', exist_ok=True)\n",
        "os.makedirs('results/sqa/model', exist_ok=True)\n",
        "with open('results/sqa/model/checkpoint', 'w') as f:\n",
        "  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "  shutil.copyfile(f'tapas_sqa_base/model.ckpt{suffix}', f'results/sqa/model/model.ckpt-0{suffix}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RlvgDAmCNtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 512\n",
        "vocab_file = \"tapas_sqa_base/vocab.txt\"\n",
        "config = tf_example_utils.ClassifierConversionConfig(\n",
        "    vocab_file=vocab_file,\n",
        "    max_seq_length=max_seq_length,\n",
        "    max_column_id=max_seq_length,\n",
        "    max_row_id=max_seq_length,\n",
        "    strip_column_names=False,\n",
        "    add_aggregation_candidates=False,\n",
        ")\n",
        "converter = tf_example_utils.ToClassifierTensorflowExample(config)\n",
        "\n",
        "def convert_interactions_to_examples(tables_and_queries):\n",
        "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
        "  for idx, (table, queries) in enumerate(tables_and_queries):\n",
        "    interaction = interaction_pb2.Interaction()\n",
        "    for position, query in enumerate(queries):\n",
        "      question = interaction.questions.add()\n",
        "      question.original_text = query\n",
        "      question.id = f\"{idx}-0_{position}\"\n",
        "    for header in table[0]:\n",
        "      interaction.table.columns.add().text = header\n",
        "    for line in table[1:]:\n",
        "      row = interaction.table.rows.add()\n",
        "      for cell in line:\n",
        "        row.cells.add().text = cell\n",
        "    number_annotation_utils.add_numeric_values(interaction)\n",
        "    for i in range(len(interaction.questions)):\n",
        "      try:\n",
        "        yield converter.convert(interaction, i)\n",
        "      except ValueError as e:\n",
        "        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
        "        \n",
        "def write_tf_example(filename, examples):\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "def predict(table_data, queries):\n",
        "  table = [list(map(lambda s: s.strip(), row.split(\"|\"))) \n",
        "           for row in table_data.split(\"\\n\") if row.strip()]\n",
        "  examples = convert_interactions_to_examples([(table, queries)])\n",
        "  write_tf_example(\"results/sqa/tf_examples/test.tfrecord\", examples)\n",
        "  write_tf_example(\"results/sqa/tf_examples/random-split-1-dev.tfrecord\", [])\n",
        "  \n",
        "  ! python tapas/tapas/run_task_main.py \\\n",
        "    --task=\"SQA\" \\\n",
        "    --output_dir=\"results\" \\\n",
        "    --noloop_predict \\\n",
        "    --test_batch_size={len(queries)} \\\n",
        "    --tapas_verbosity=\"ERROR\" \\\n",
        "    --compression_type= \\\n",
        "    --init_checkpoint=\"tapas_sqa_base/model.ckpt\" \\\n",
        "    --bert_config_file=\"tapas_sqa_base/bert_config.json\" \\\n",
        "    --mode=\"predict\" 2> error\n",
        "\n",
        "\n",
        "  results_path = \"results/sqa/model/test_sequence.tsv\"\n",
        "  all_coordinates = []\n",
        "  df = pd.DataFrame(table[1:], columns=table[0])\n",
        "  display(IPython.display.HTML(df.to_html(index=False)))\n",
        "  print()\n",
        "  with open(results_path) as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "    for row in reader:\n",
        "      coordinates = prediction_utils.parse_coordinates(row[\"answer_coordinates\"])\n",
        "      all_coordinates.append(coordinates)\n",
        "      answers = ', '.join([table[row + 1][col] for row, col in coordinates])\n",
        "      position = int(row['position'])\n",
        "      print(\">\", queries[position])\n",
        "      print(answers)\n",
        "  return all_coordinates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqu-I-M9QaoA",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIE7bTJMVuSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "faf21467-51cd-46d3-e782-919125eb14fa"
      },
      "source": [
        "# Example nu-1000-0\n",
        "result = predict(\"\"\"\n",
        "Pos | No | Driver               | Team                           | Laps | Time/Retired | Grid | Points\n",
        "1   | 32 | Patrick Carpentier   | Team Player's                  | 87   | 1:48:11.023  | 1    | 22    \n",
        "2   | 1  | Bruno Junqueira      | Newman/Haas Racing             | 87   | +0.8 secs    | 2    | 17    \n",
        "3   | 3  | Paul Tracy           | Team Player's                  | 87   | +28.6 secs   | 3    | 14\n",
        "4   | 9  | Michel Jourdain, Jr. | Team Rahal                     | 87   | +40.8 secs   | 13   | 12\n",
        "5   | 34 | Mario Haberfeld      | Mi-Jack Conquest Racing        | 87   | +42.1 secs   | 6    | 10\n",
        "6   | 20 | Oriol Servia         | Patrick Racing                 | 87   | +1:00.2      | 10   | 8 \n",
        "7   | 51 | Adrian Fernandez     | Fernandez Racing               | 87   | +1:01.4      | 5    | 6\n",
        "8   | 12 | Jimmy Vasser         | American Spirit Team Johansson | 87   | +1:01.8      | 8    | 5\n",
        "9   | 7  | Tiago Monteiro       | Fittipaldi-Dingman Racing      | 86   | + 1 Lap      | 15   | 4\n",
        "10  | 55 | Mario Dominguez      | Herdez Competition             | 86   | + 1 Lap      | 11   | 3\n",
        "11  | 27 | Bryan Herta          | PK Racing                      | 86   | + 1 Lap      | 12   | 2\n",
        "12  | 31 | Ryan Hunter-Reay     | American Spirit Team Johansson | 86   | + 1 Lap      | 17   | 1\n",
        "13  | 19 | Joel Camathias       | Dale Coyne Racing              | 85   | + 2 Laps     | 18   | 0\n",
        "14  | 33 | Alex Tagliani        | Rocketsports Racing            | 85   | + 2 Laps     | 14   | 0\n",
        "15  | 4  | Roberto Moreno       | Herdez Competition             | 85   | + 2 Laps     | 9    | 0\n",
        "16  | 11 | Geoff Boss           | Dale Coyne Racing              | 83   | Mechanical   | 19   | 0\n",
        "17  | 2  | Sebastien Bourdais   | Newman/Haas Racing             | 77   | Mechanical   | 4    | 0\n",
        "18  | 15 | Darren Manning       | Walker Racing                  | 12   | Mechanical   | 7    | 0\n",
        "19  | 5  | Rodolfo Lavin        | Walker Racing                  | 10   | Mechanical   | 16   | 0\n",
        "\"\"\", [\"what were the drivers names?\",\n",
        "      \"of these, which points did patrick carpentier and bruno junqueira score?\",\n",
        "      \"who scored higher?\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_built_with_cuda: True\n",
            "is_gpu_available: False\n",
            "GPUs: []\n",
            "Training or predicting ...\n",
            "Evaluation finished after training step 0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Pos</th>\n",
              "      <th>No</th>\n",
              "      <th>Driver</th>\n",
              "      <th>Team</th>\n",
              "      <th>Laps</th>\n",
              "      <th>Time/Retired</th>\n",
              "      <th>Grid</th>\n",
              "      <th>Points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Patrick Carpentier</td>\n",
              "      <td>Team Player's</td>\n",
              "      <td>87</td>\n",
              "      <td>1:48:11.023</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Bruno Junqueira</td>\n",
              "      <td>Newman/Haas Racing</td>\n",
              "      <td>87</td>\n",
              "      <td>+0.8 secs</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Paul Tracy</td>\n",
              "      <td>Team Player's</td>\n",
              "      <td>87</td>\n",
              "      <td>+28.6 secs</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>Michel Jourdain, Jr.</td>\n",
              "      <td>Team Rahal</td>\n",
              "      <td>87</td>\n",
              "      <td>+40.8 secs</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>Mario Haberfeld</td>\n",
              "      <td>Mi-Jack Conquest Racing</td>\n",
              "      <td>87</td>\n",
              "      <td>+42.1 secs</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>Oriol Servia</td>\n",
              "      <td>Patrick Racing</td>\n",
              "      <td>87</td>\n",
              "      <td>+1:00.2</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>51</td>\n",
              "      <td>Adrian Fernandez</td>\n",
              "      <td>Fernandez Racing</td>\n",
              "      <td>87</td>\n",
              "      <td>+1:01.4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>Jimmy Vasser</td>\n",
              "      <td>American Spirit Team Johansson</td>\n",
              "      <td>87</td>\n",
              "      <td>+1:01.8</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>Tiago Monteiro</td>\n",
              "      <td>Fittipaldi-Dingman Racing</td>\n",
              "      <td>86</td>\n",
              "      <td>+ 1 Lap</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>55</td>\n",
              "      <td>Mario Dominguez</td>\n",
              "      <td>Herdez Competition</td>\n",
              "      <td>86</td>\n",
              "      <td>+ 1 Lap</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>Bryan Herta</td>\n",
              "      <td>PK Racing</td>\n",
              "      <td>86</td>\n",
              "      <td>+ 1 Lap</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>Ryan Hunter-Reay</td>\n",
              "      <td>American Spirit Team Johansson</td>\n",
              "      <td>86</td>\n",
              "      <td>+ 1 Lap</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>Joel Camathias</td>\n",
              "      <td>Dale Coyne Racing</td>\n",
              "      <td>85</td>\n",
              "      <td>+ 2 Laps</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>33</td>\n",
              "      <td>Alex Tagliani</td>\n",
              "      <td>Rocketsports Racing</td>\n",
              "      <td>85</td>\n",
              "      <td>+ 2 Laps</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>Roberto Moreno</td>\n",
              "      <td>Herdez Competition</td>\n",
              "      <td>85</td>\n",
              "      <td>+ 2 Laps</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>Geoff Boss</td>\n",
              "      <td>Dale Coyne Racing</td>\n",
              "      <td>83</td>\n",
              "      <td>Mechanical</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>Sebastien Bourdais</td>\n",
              "      <td>Newman/Haas Racing</td>\n",
              "      <td>77</td>\n",
              "      <td>Mechanical</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>Darren Manning</td>\n",
              "      <td>Walker Racing</td>\n",
              "      <td>12</td>\n",
              "      <td>Mechanical</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>Rodolfo Lavin</td>\n",
              "      <td>Walker Racing</td>\n",
              "      <td>10</td>\n",
              "      <td>Mechanical</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> what were the drivers names?\n",
            "Bruno Junqueira, Joel Camathias, Michel Jourdain, Jr., Alex Tagliani, Tiago Monteiro, Geoff Boss, Rodolfo Lavin, Mario Dominguez, Ryan Hunter-Reay, Sebastien Bourdais, Darren Manning, Adrian Fernandez, Paul Tracy, Mario Haberfeld, Roberto Moreno, Oriol Servia, Patrick Carpentier, Jimmy Vasser, Bryan Herta\n",
            "> of these, which points did patrick carpentier and bruno junqueira score?\n",
            "22, 17\n",
            "> who scored higher?\n",
            "Patrick Carpentier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUCRa7qthkbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "a7a4e7e6-dad8-47e9-da4f-e091daf3665c"
      },
      "source": [
        "result = predict(\"\"\"ID | Name | Age | Salary\n",
        "                    1 | Chetan Chauhan | 31 | 2000\n",
        "                    2 | Niharika Sengar | 32 | 4000\n",
        "                    3 | Beenu Singh | 35 | 3000\n",
        "                  \"\"\", [\"Whose Salary is Highest?\", \"What is the Average Age?\", \"Whose Age is not 31 or 35 and greater than 40?\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_built_with_cuda: True\n",
            "is_gpu_available: False\n",
            "GPUs: []\n",
            "Training or predicting ...\n",
            "Evaluation finished after training step 0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Chetan Chauhan</td>\n",
              "      <td>31</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Niharika Sengar</td>\n",
              "      <td>32</td>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Beenu Singh</td>\n",
              "      <td>35</td>\n",
              "      <td>3000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Whose Salary is Highest?\n",
            "Niharika Sengar\n",
            "> What is the Average Age?\n",
            "32\n",
            "> Whose Age is not 31 or 35 and greater than 40?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeVrlw2LiddY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}